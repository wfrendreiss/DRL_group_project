Number of model parameters: 1.98e+08
Result contains:  dict_keys(['embeds', 'action_logits', 'return_logits', 'reward_logits', 'loss', 'accuracy'])
step: 0 done: [0 0 0 0] reward: [0. 0. 0. 0.]
step: 100 done: [0 0 0 0] reward: [2. 2. 2. 2.]
step: 200 done: [0 0 0 0] reward: [6. 6. 6. 6.]
step: 300 done: [0 0 0 0] reward: [9. 9. 9. 7.]
step: 400 done: [0 0 0 0] reward: [11. 11. 11.  8.]
step: 500 done: [0 0 0 0] reward: [14. 18. 13. 12.]
step: 600 done: [0 0 0 0] reward: [17. 22. 20. 15.]
step: 700 done: [0 0 0 0] reward: [19. 26. 23. 17.]
step: 800 done: [0 0 0 0] reward: [29. 36. 25. 20.]
step: 900 done: [0 0 0 0] reward: [31. 42. 28. 27.]
step: 1000 done: [0 0 0 0] reward: [36. 55. 34. 36.]
step: 1100 done: [0 0 0 0] reward: [38. 68. 40. 45.]
step: 1200 done: [0 0 0 0] reward: [ 47. 101.  46.  57.]
step: 1300 done: [0 0 0 0] reward: [ 74. 199.  54.  73.]
step: 1400 done: [0 0 0 0] reward: [ 86. 277.  71.  97.]
step: 1500 done: [1 0 0 0] reward: [109. 312.  89. 124.]
step: 1600 done: [1 0 0 0] reward: [109. 312. 125. 229.]
step: 1700 done: [1 0 0 0] reward: [109. 312. 152. 229.]
step: 1800 done: [1 0 0 1] reward: [109. 312. 176. 289.]
step: 1900 done: [1 0 0 1] reward: [109. 312. 194. 289.]
step: 2000 done: [1 0 0 1] reward: [109. 312. 216. 289.]
step: 2100 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2200 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2300 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2400 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2500 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2600 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2700 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2800 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 2900 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3000 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3100 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3200 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3300 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3400 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3500 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3600 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3700 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3800 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 3900 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4000 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4100 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4200 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4300 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4400 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4500 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4600 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4700 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4800 done: [1 0 1 1] reward: [109. 312. 300. 289.]
step: 4900 done: [1 0 1 1] reward: [109. 312. 300. 289.]
scores: [109. 312. 300. 289.] average score: 252.5
total score: mean: 252.5 std: 83.24812316894531 max: 312.0
